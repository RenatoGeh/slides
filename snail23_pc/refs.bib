@article{darwiche02,
	year = 2002,
	month = {sep},
	publisher = {{AI} Access Foundation},
	volume = {17},
	pages = {229--264},
	author = {A. Darwiche and P. Marquis},
	title = {A Knowledge Compilation Map},
	journal = {Journal of Artificial Intelligence Research}
}

@article{vergari21,
  title={A Compositional Atlas of Tractable Circuit Operations: From Simple Transformations to Complex Information-Theoretic Queries},
  author={Antonio Vergari and YooJung Choi and Anji Liu and Stefano Teso and Guy Van den Broeck},
  year={2021},
  journal   = {CoRR},
  volume    = {abs/2102.06137},
  archivePrefix = {arXiv},
  eprint={2102.06137}
}

@inproceedings{poon11,
  author = {Poon, Hoifung and Domingos, Pedro},
  title = {Sum-Product Networks: A New Deep Architecture},
  year = {2011},
  booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
  pages = {337--346}
}

@article{peharz16,
  title={On the latent variable interpretation in sum-product networks},
  author={Peharz, Robert and Gens, Robert and Pernkopf, Franz and Domingos, Pedro},
  journal={{IEEE} transactions on pattern analysis and machine intelligence},
  volume={39},
  number={10},
  pages={2030--2044},
  year={2016}
}

@inproceedings{conaty17,
  author    = {Diarmaid Conaty and
               Cassio Polpo de Campos and
               Denis Deratani Mau{\'{a}}},
  title     = {Approximation Complexity of Maximum {A} Posteriori Inference in Sum-Product
               Networks},
  booktitle = {Proceedings of the Thirty-Third Conference on Uncertainty in Artificial
               Intelligence},
  year      = {2017},
}

@article{kisa14,
  author = {Doga Kisa and Guy Van den Broeck and Arthur Choi and Adnan Darwiche},
  title = {Probabilistic Sentential Decision Diagrams},
  journal = {Knowledge Representation and Reasoning Conference},
  year = {2014},
  abstract = {We propose the Probabilistic Sentential Decision Diagram (PSDD): A complete and canonical representation of probability distributions defined over the models of a given propositional theory.  Each parameter of a PSDD can be viewed as the (conditional) probability of making a decision in a corresponding Sentential Decision Diagram (SDD). The SDD itself is a recently proposed complete and canonical representation of propositional theories.  We explore a number of interesting properties of PSDDs, including the independencies that underlie them.  We show that the PSDD is a tractable representation.  We further show how the parameters of a PSDD can be efficiently estimated, in closed form, from complete data.  We empirically evaluate the quality of PSDDs learned from data, when we have knowledge, a priori, of the domain logical constraints.},
}

@inproceedings{zhang23,
  title         = {Tractable Control for Autoregressive Language Generation},
  author        = {Zhang, Honghua and Dang, Meihua and Peng, Nanyun and Van den Broeck, Guy},
  booktitle     = {Proceedings of the 40th International Conference on Machine Learning (ICML)},
  year          = {2023},
}

@misc{skryagin23,
      title={Scalable Neural-Probabilistic Answer Set Programming},
      author={Arseny Skryagin and Daniel Ochs and Devendra Singh Dhami and Kristian Kersting},
      year={2023},
      eprint={2306.08397},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{kareem22,
 author = {Ahmed, Kareem and Teso, Stefano and Chang, Kai-Wei and Van den Broeck, Guy and Vergari, Antonio},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {29944--29959},
 publisher = {Curran Associates, Inc.},
 title = {Semantic Probabilistic Layers for Neuro-Symbolic Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/c182ec594f38926b7fcb827635b9a8f4-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@article{manhaeve21,
title = {Neural probabilistic logic programming in DeepProbLog},
journal = {Artificial Intelligence},
volume = {298},
pages = {103504},
year = {2021},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2021.103504},
url = {https://www.sciencedirect.com/science/article/pii/S0004370221000552},
author = {Robin Manhaeve and Sebastijan Dumančić and Angelika Kimmig and Thomas Demeester and Luc {De Raedt}},
keywords = {Logic, Probability, Neural networks, Probabilistic logic programming, Neuro-symbolic integration, Learning and reasoning},
abstract = {We introduce DeepProbLog, a neural probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques of the underlying probabilistic logic programming language ProbLog can be adapted for the new language. We theoretically and experimentally demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples.}
}
